{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtGUfALarTIY"
      },
      "outputs": [],
      "source": [
        "# Data Management Project\n",
        "# Team 6"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pymongo # for MongoDB\n",
        "import psycopg2 # for PostgresQL\n",
        "import pandas as pd "
      ],
      "metadata": {
        "id": "044rXH9u5g-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        " \n",
        "def get_text_sorted(text):\n",
        "\n",
        "  res = [re.sub(r'[^\\w\\s]', '', s) for s in list(set(text.lower().split()))]\n",
        "  res.sort()\n",
        "  return res\n",
        "\n",
        "def get_hashtags_sorted(hlist):\n",
        "  hlist.sort()\n",
        "  return hlist"
      ],
      "metadata": {
        "id": "Rxdxv7zVEGSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pymongo\n",
        "from google.colab import drive\n",
        "import time\n",
        "import datetime\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "iNR35ws8QcyF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b181cc36-24ca-4fa6-bef2-8e8d0025991c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Storing the Data"
      ],
      "metadata": {
        "id": "NNrDrnMkrV4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = pymongo.MongoClient(\"mongodb://localhost:27017/\") \n",
        "db = client[\"myDB\"]\n",
        "tweets=db[\"tweets_table\"]"
      ],
      "metadata": {
        "id": "VGe4bwVyQCei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweets.create_index([('created_at', pymongo.DESCENDING)])\n",
        "tweets.create_index([('user_id', pymongo.ASCENDING)])\n",
        "tweets.create_index([('id', pymongo.DESCENDING)])"
      ],
      "metadata": {
        "id": "FwAFwApBBbBu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "outputId": "dfe358a9-4343-4153-c35f-e30ded6f2a9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ServerSelectionTimeoutError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mServerSelectionTimeoutError\u001b[0m               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-f85f6e1d1f51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtweets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'created_at'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpymongo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDESCENDING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtweets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'user_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpymongo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mASCENDING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pymongo/collection.py\u001b[0m in \u001b[0;36mcreate_index\u001b[0;34m(self, keys, session, comment, **kwargs)\u001b[0m\n\u001b[1;32m   2021\u001b[0m             \u001b[0mcmd_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"comment\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2022\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIndexModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2023\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__create_indexes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcmd_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2024\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2025\u001b[0m     def drop_indexes(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pymongo/collection.py\u001b[0m in \u001b[0;36m__create_indexes\u001b[0;34m(self, indexes, session, **kwargs)\u001b[0m\n\u001b[1;32m   1877\u001b[0m         \"\"\"\n\u001b[1;32m   1878\u001b[0m         \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1879\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_socket_for_writes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msock_info\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1880\u001b[0m             \u001b[0msupports_quorum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msock_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_wire_version\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pymongo/collection.py\u001b[0m in \u001b[0;36m_socket_for_writes\u001b[0;34m(self, session)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_socket_for_writes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__database\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_socket_for_writes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     def _command(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pymongo/mongo_client.py\u001b[0m in \u001b[0;36m_socket_for_writes\u001b[0;34m(self, session)\u001b[0m\n\u001b[1;32m   1204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_socket_for_writes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1206\u001b[0;31m         \u001b[0mserver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_select_server\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwritable_server_selector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1207\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pymongo/mongo_client.py\u001b[0m in \u001b[0;36m_select_server\u001b[0;34m(self, server_selector, session, address)\u001b[0m\n\u001b[1;32m   1194\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mAutoReconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"server %s:%d no longer available\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0maddress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1196\u001b[0;31m                 \u001b[0mserver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopology\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_server\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserver_selector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1197\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mserver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mPyMongoError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pymongo/topology.py\u001b[0m in \u001b[0;36mselect_server\u001b[0;34m(self, selector, server_selection_timeout, address)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mselect_server\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver_selection_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maddress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;34m\"\"\"Like select_servers, but choose a random server if several match.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0mservers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_servers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver_selection_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maddress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mservers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mservers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pymongo/topology.py\u001b[0m in \u001b[0;36mselect_servers\u001b[0;34m(self, selector, server_selection_timeout, address)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m             \u001b[0mserver_descriptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_select_servers_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maddress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_server_by_address\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msd\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mserver_descriptions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pymongo/topology.py\u001b[0m in \u001b[0;36m_select_servers_loop\u001b[0;34m(self, selector, timeout, address)\u001b[0m\n\u001b[1;32m    227\u001b[0m                 raise ServerSelectionTimeoutError(\n\u001b[1;32m    228\u001b[0m                     \u001b[0;34m\"%s, Timeout: %ss, Topology Description: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m                     \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_error_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m                 )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mServerSelectionTimeoutError\u001b[0m: localhost:27017: [Errno 111] Connection refused, Timeout: 30s, Topology Description: <TopologyDescription id: 6261972cfd9fe723beeaf7ad, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [Errno 111] Connection refused')>]>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tweets.create_index([('text', 'text')])\n",
        "def search_by_text_index(word):\n",
        "  return tweets.find({'$text': {'$search':word}})"
      ],
      "metadata": {
        "id": "eXWxtaOFpPt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_JSON_date(s):\n",
        "  d=s.split()\n",
        "  t=d[3].split(':')\n",
        "  months={'Jan':1, 'Feb':2, 'Mar':3, 'Apr':4, 'May':5, 'Jun':6, 'Jul':7, 'Aug':8, 'Sep':9, 'Oct':10, 'Nov':11, 'Dec':12}\n",
        "  m=datetime.datetime(day=int(d[2]), month=months[d[1]], hour=int(t[0]), minute=int(t[1]), second=int(t[2]), microsecond=int(d[4]), year=int(d[5]))\n",
        "\n",
        "  return m.isoformat()"
      ],
      "metadata": {
        "id": "42krp2kLINrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from Jinwoo\n",
        "\n",
        "# connecting to the database\n",
        "conn = psycopg2.connect(\n",
        "    host = \"localhost\", #localhost\n",
        "    port = \"5432\", #yourport\n",
        "    database = \"postgres\", # databasename\n",
        "    user=\"postgres\",\n",
        "    password = \"Vicis9423*\"\n",
        ")\n",
        "cur = conn.cursor() # make  cursor \n",
        "\n",
        "\n",
        "# creating user and hashtage table\n",
        "cur.execute(\"ROLLBACK\")\n",
        "cur.execute(\"CREATE TABLE user_db (screen_name VARCHAR (100) PRIMARY KEY, user_id int,followers_count int, tweet_ids integer[]);\")"
      ],
      "metadata": {
        "id": "yErbcrPDvsVg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "outputId": "d28e41c1-3bac-41e6-9a00-d7971bdd048f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b82ce0f1d012>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# connecting to the database\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m conn = psycopg2.connect(\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mhost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"localhost\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#localhost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"5432\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#yourport\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'psycopg2' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for Inserting values to user_db and hashtag_db (PostgreSQL)\n",
        "\n",
        "def insert_to_userdb(screen_name,user_id,followers_count,tweet_id):\n",
        "    \"\"\" insert values into the user table \"\"\"\n",
        "    \n",
        "    sql = \"\"\"INSERT INTO user_db(screen_name, user_id ,followers_count, tweet_ids) VALUES(%s,%s,%s,%s);\"\"\"\n",
        "    try:\n",
        "        # execute the INSERT statement\n",
        "        cur.execute(\"ROLLBACK\")\n",
        "        cur.execute(sql, (screen_name,user_id,followers_count,tweet_id))\n",
        "    except (Exception, psycopg2.DatabaseError) as error:\n",
        "        print(error)\n",
        "\n",
        "def update_tweet_ids_userdb(screen_name_,tweet_id):\n",
        "  \"\"\" update values into the userdb table \"\"\"\n",
        "\n",
        "  sql =   \"\"\"\n",
        "  UPDATE user_db1 SET tweet_ids = array_append((SELECT tweet_ids FROM user_db1 WHERE screen_name=(%s)),(%s)) WHERE screen_name = (%s)  \n",
        "  \"\"\"\n",
        "  try:\n",
        "      # execute the UPDATE statement\n",
        "      cur.execute(\"ROLLBACK\")\n",
        "      cur.execute(sql, (screen_name_,tweet_id,screen_name_))\n",
        "  except (Exception, psycopg2.DatabaseError) as error:\n",
        "      print(error) \n",
        "\n"
      ],
      "metadata": {
        "id": "1uNPliaa2zaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the userdb\n",
        "cur.execute(\"ROLLBACK\")\n",
        "userdb = cur.execute(\"\"\"SELECT * FROM userdb\"\"\")"
      ],
      "metadata": {
        "id": "bsp1dZVrvmVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#with open(\"corona-out-2\", \"r\") as f1:\n",
        "with open('/content/gdrive/My Drive/corona-out-2', \"r\") as f1:\n",
        "    for line in f1:\n",
        "        try:\n",
        "          data = json.loads(line)\n",
        "          myquery = { 'id': data['id'] }\n",
        "          mydoc = tweets.find(myquery)\n",
        "\n",
        "\n",
        "\n",
        "          # get the userdb\n",
        "          cur.execute(\"ROLLBACK\")\n",
        "          user_db =  pd.read_sql_query('select * from \"user_db\"',con=conn) # dataframe format\n",
        "\n",
        "\n",
        "            # pseudocode: \n",
        "            # if tweet has been seen before, \n",
        "            #         continue (ignore this tweet, go to next iteration of loop)\n",
        "          if len(list(mydoc))==0:\n",
        "            user = data['user']\n",
        "            #add_user(user)\n",
        "            # psuedocode: \n",
        "            # if user has not been seen before\n",
        "            #            add to user table \n",
        "            # update datastores with any metrics that you are tracking \n",
        "            \n",
        "            if ( data['text'].startswith('RT') ):\n",
        "              retweet_data={'id':data['id'], 'created_at':get_JSON_date(data['created_at']), 'user_id':data['user']['id']}\n",
        "              tdata=data['retweeted_status']\n",
        "              myquery={'id':tdata['id']}\n",
        "              original_tweet = tweets.find(myquery)\n",
        "              if len(list(original_tweet))==0:\n",
        "                tweets.insert_one({'id':tdata['id'], 'text':tdata['text'], 'text_sorted':get_text_sorted(data['text']), 'created_at':get_JSON_date(tdata['created_at']), 'user_id':tdata['user']['id'], 'favorite_count':tdata['favorite_count'], 'retweet_count':tdata['retweet_count'], 'interactions':tdata['favorite_count']+tdata['retweet_count'], 'hashtags':get_hashtags_sorted([x['text'].lower() for x in tdata['entities']['hashtags']]), 'retweets':[retweet_data]})\n",
        "              \n",
        "                # USER DB\n",
        "           #     if tdata['user']['id'] in user_db:\n",
        "           #       if tdata['id'] not in get_user_db_tweetlist(tdata['id'],'tweet_list'):\n",
        "          #          update_tweet_list_userdb(tdata['user']'id'],tdata['id'])\n",
        "            #    else:\n",
        "             #     insert_to_userdb(tdata['user']['id'], tdata['user']['name'], tdata['favorite_count'],tdata['id'])\n",
        "\n",
        "\n",
        "                # USER DB\n",
        "                if tdata['user']['screen_name'] in list(user_db['screen_name']):\n",
        "                  if tdata['id'] not in list(user_db['tweet_ids']):\n",
        "                    update_tweet_ids_userdb(tdata['user']['screen_name'],tdata['id'])\n",
        "                  else:\n",
        "                    insert_to_userdb(tdata['user']['screen_name'], tdata['user']['id'], tdata['favorite_count'], [tdata['id']] )\n",
        "\n",
        "\n",
        "              else:\n",
        "               # retweets=original_tweet['retweets']\n",
        "               # retweets.append(retweet_data)\n",
        "                tweets.update_one(myquery, {'$push': {'retweets': retweet_data}})\n",
        "                # psuedocode:\n",
        "                # update retweet information\n",
        "                # note that you may not have an entry for the original tweet \n",
        "                # if that is not in the dataset, put it in\n",
        "\n",
        "            else:\n",
        "              \n",
        "              tweets.insert_one({'id':data['id'], 'text':data['text'], 'text_sorted':get_text_sorted(data['text']), 'created_at':get_JSON_date(data['created_at']), 'user_id':data['user']['id'], 'favorite_count':data['favorite_count'], 'retweet_count':data['retweet_count'], 'interactions':data['favorite_count']+data['retweet_count'], 'hashtags':get_hashtags_sorted([x['text'].lower() for x in data['entities']['hashtags']]), 'retweets':list()})\n",
        "\n",
        "\n",
        "            # USER DB\n",
        "            if data['user']['screen_name'] in list(user_db['screen_name']):\n",
        "              if data['id'] not in list(user_db['tweet_ids']):\n",
        "                update_tweet_ids_userdb(data['user']['screen_name'],data['id'])\n",
        "            else:\n",
        "                insert_to_userdb(data['user']['screen_name'], data['user']['id'], data['favorite_count'], [data['id']] )\n",
        "\n",
        "                \n",
        "        except:\n",
        "          continue\n",
        "\n"
      ],
      "metadata": {
        "id": "Tg8LLj8dQsoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def binary_search(arr, low, high, s):\n",
        " \n",
        "    if high >= low:\n",
        " \n",
        "        mid = (high + low) // 2\n",
        " \n",
        "        if arr[mid] == s:\n",
        "            return True\n",
        " \n",
        "        elif arr[mid] > s:\n",
        "            return binary_search(arr, low, mid - 1, s)\n",
        " \n",
        "        else:\n",
        "            return binary_search(arr, mid + 1, high, s)\n",
        " \n",
        "    else:\n",
        "        return False\n",
        "\n",
        "def search_by_text_or_ht(s, para):\n",
        "  #para can be hashtags or text_sorted\n",
        "  ret=list()\n",
        "  for doc in tweets.find().sort('interactions', -1):\n",
        "    if binary_search(doc[para], 0, len(doc)-1, s):\n",
        "      ret.append(doc)\n",
        "\n",
        "\n",
        "def time_range_search(t1, t2):\n",
        "  #query={'$and':{[{'created_at':{'$gt':t1}}, {'created_at':{'$lt':t2}}]}}\n",
        "  query={'created_at':{'$gt':t1}, 'created_at':{'$lt':t2}}\n",
        "  return tweets.find(query).sort('interactions', -1)\n",
        "\n",
        "\n",
        "def top_10_tweets():\n",
        "  return tweets.find().sort('interactions', -1).limit(10)\n",
        "\n",
        "\n",
        "# need to be optimzied \n",
        "def get_tweet_id_by_user_name(user_name):\n",
        "  user_db = pd.read_sql(\"SELECT * FROM user_db\",con=conn) # **** need to optimize\n",
        "  return list(user_db[user_db['screen_name'] == user_name]['tweet_ids'])\n",
        "\n",
        "\n",
        "\n",
        "def search_by_user(user_name):\n",
        "  tweet_ids = get_tweet_id_by_user_name(user_name)\n",
        "#want a get_user_name_by_user_id for meta data\n",
        "  res=list()\n",
        "  for tweet_id in tweet_ids:\n",
        "      query={'id': tweet_id}\n",
        "      for doc in tweets.find(query):\n",
        "        res.append(doc)\n",
        "  \n",
        "  "
      ],
      "metadata": {
        "id": "4SlFH_lj2oQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zGH5mqPX4x9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Relational"
      ],
      "metadata": {
        "id": "_3HZuMXbrYrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##NoSQL"
      ],
      "metadata": {
        "id": "fcW8tROVrbId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "43N2P1Fmrecr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cache"
      ],
      "metadata": {
        "id": "c88PtFT2YRMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import redis\n",
        "import json\n",
        "from bson.json_util import dumps\n",
        "from pymongo import MongoClient\n",
        "client = MongoClient('mongodb://localhost:27017/')\n",
        "redisClient = redis.StrictRedis(host='localhost', port=6379, db=0)\n",
        "\n",
        "database = client['DummyDb'] #database name in mongodb\n",
        "userList = database['Users'].find() #collection name in 'DummyDb' database\n",
        "\n",
        "serializedObj = dumps(userList) #serialize object for the set redis.\n",
        "result = redisClient.set('users', serializedObj) #set serialized object to redis server.\n",
        "\n",
        "#you can check the users in redis using redis gui or type 'get users' to redis client or just get it from the redis like below.\n",
        "parsedUserList = json.loads(redisClient.get('users'))\n",
        "\n",
        "for user in parsedUserList: #check the names\n",
        "\tprint(user[\"username\"]) #'username' one of the field of the 'Users' collection"
      ],
      "metadata": {
        "id": "i9IMrE3IISEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite\n",
        "import redis\n",
        "import json\n",
        "\n",
        "def get_tweet_data():\n",
        "  connection = sqlite3.connect(database = \"database.db\")\n",
        "  cursor = connection.cursor()\n",
        "  redis_client = redis.Redis()\n",
        "\n",
        "  cached_tweets = redis_client.get(\"tweet data\") # Name of Key in cache\n",
        "  if cached_tweet is not None:\n",
        "    return json.load(cached_tweet)\n",
        "\n",
        "  curson.execute(\"SELECT id, name FROM users;\")\n",
        "  result = cursor.fetchall()\n",
        "\n",
        "  redis_client.set(name = \"tweet data\", value = json.dump(result), ex=60)  # Key = \"tweet data\",  Value = \"result as json format\" , ex mean expiration time\n",
        "\n",
        "  cursor.close()\n",
        "  connection.close()\n",
        "  redis_client.close()\n",
        "  return result\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  print(get_tweet_data())\n",
        "\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "L5riNQNgFkej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cache\n",
        "\n",
        "# Sample\n",
        "import redis\n",
        "import pymysql\n",
        "import time\n",
        "\n",
        "# 레디스 클라이언트를 만든다\n",
        "# Redis<ConnectionPool<Connection>>\n",
        "r = redis.Redis(host=\"192.168.88.244\", port=6379, password=\"password\", \n",
        "                decode_responses=True)\n",
        "                \n",
        "#pymysql로 mysql 연결\n",
        "mysql_db = pymysql.connect(\n",
        "    user=\"root\",\n",
        "    passwd=\"password\",\n",
        "    host=\"192.168.88.244\",\n",
        "    port=7676,\n",
        "    db=\"employees\",\n",
        "    charset = \"utf8\"\n",
        ")\n",
        "\n",
        "#여기부터 실제 로직\n",
        "result_list = []\n",
        "#id=int(input(\"emp_no 입력 (6자리)\")) #직접입력귀찮아서;\n",
        "for emp_no in range(10200,10300):\n",
        "    id= int(emp_no)\n",
        "    first_time = time.time()\n",
        "    result = r.get(name=id)\n",
        "    print(id)\n",
        "\n",
        "    if not result:\n",
        "        print(\"캐시에서 가져오지 못함\")\n",
        "        cursor = mysql_db.cursor()\n",
        "        sql = '''select emp_no,first_name from employees where emp_no=%s'''\n",
        "        cursor.execute(sql, (int(id)))\n",
        "        result = cursor.fetchone()\n",
        "        r.set(name=result[0], value=result[1])\n",
        "\n",
        "\n",
        "    else:\n",
        "        print(\"캐시에서 가져옴!\")\n",
        "\n",
        "    result = r.get(name=id) #if문에 넣을수있지만 동일한 조건을 주기위함\n",
        "    last_time = time.time()\n",
        "    timetotime = last_time-first_time\n",
        "    print(timetotime, \"초 걸림\")\n",
        "    print(result)\n",
        "    result_list.append(timetotime)\n",
        "    \n",
        "print(\"완료\")\n",
        "print(sum(result_list)/len(result_list)"
      ],
      "metadata": {
        "id": "4vs-fqZTYW5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Search"
      ],
      "metadata": {
        "id": "-UyWhibzrgmP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#based on the script above\n",
        "#binary search\n",
        "#how are we planning to store retweet data into MongoDB\n",
        "#seach text,hashtag together or seperate\n",
        "#DB connect when?\n",
        "#search by text needs to be optimized depenging performance\n",
        "\n",
        "tweets.create_index(\"hashtags\")\n",
        "tweets.create_index([('text', pymongo.ASCENDING)])\n",
        "\n",
        "# Create hashtag to tweet_id to hash table\n",
        "hash_tag_tweet_id = {}\n",
        "for tweet in tweets:\n",
        "    hast_tags = tweet.get('hashtags')\n",
        "    for hash_tag in hast_tags:\n",
        "        if hash_tag_tweet_id[hast_tag].count() == 0:\n",
        "            hash_tag_tweet_id[hast_tag] = [tweet.get('id')]\n",
        "        else:\n",
        "            hash_tag_tweet_id[hash_tag].append(tweet.get('id'))\n",
        "            \n",
        "# Create interaction field in tweet mongoDB\n",
        "def calculate_interaction():\n",
        "    def transform(doc):\n",
        "        retweet_count = len(tweet['retweets'])\n",
        "        favorite_count = int(tweet.get('favorites'))\n",
        "        doc['interactions'] = retweet_count + favorite_count\n",
        "    return transform\n",
        "\n",
        "tweet.update(calculate_interaction())\n",
        "tweets.create_index([('interactions', pymongo.DESCENDING)])\n",
        "\n",
        "\n",
        "def binary_search(arr, low, high, s):\n",
        " \n",
        "    if high >= low:\n",
        " \n",
        "        mid = (high + low) // 2\n",
        " \n",
        "        if arr[mid] == s:\n",
        "            return True\n",
        " \n",
        "        elif arr[mid] > s:\n",
        "            return binary_search(arr, low, mid - 1, s)\n",
        " \n",
        "        else:\n",
        "            return binary_search(arr, mid + 1, high, s)\n",
        " \n",
        "    else:\n",
        "        return False\n",
        "    \n",
        "def search_by_text_or_ht(s, para):\n",
        "  #para can be hashtags or text_sorted\n",
        "  ret=list()\n",
        "  for doc in tweets.find().sort('interactions', -1):\n",
        "    if binary_search(doc[para], 0, len(doc)-1, s):\n",
        "      ret.append(doc)\n",
        "    \n",
        "# Find tweets by list of ids\n",
        "def get_tweet_by_ids(tweet_ids):\n",
        "    return tweets.find({'id':{$in:tweet_ids}}).sort('interactions', -1)\n",
        "\n",
        "# Search directly into text field in tweet db using case-insensitve regex match\n",
        "# Text field is indexed\n",
        "# This might need optimization(still in progress)\n",
        "def search_by_text(text):\n",
        "    text = '/' + str(text) + '/i'\n",
        "    return tweets.find({\"text\": re.compile(text, re.IGNORECASE)}).sort('interactions', -1)\n",
        "\n",
        "# Search of hashtag key in hash_tag_tweet_id table\n",
        "# After finding the value, list of tweet ids, for the hashtag\n",
        "# find the tweets for those tweet ids\n",
        "def search_by_hashtag(ht):\n",
        "    if hash_tag_tweet_id.has_key(ht):\n",
        "        tweet_ids =  hash_tag_tweet_id[ht]\n",
        "        return get_tweet_by_ids(tweet_ids)\n",
        "    else:\n",
        "        return 'No Tweets for this hashtag'\n",
        "            \n",
        "def time_range_search(t1, t2):\n",
        "    #query={'$and':{[{'created_at':{'$gt':t1}}, {'created_at':{'$lt':t2}}]}}\n",
        "    query={'created_at':{'$gt':t1}, 'created_at':{'$lt':t2}}\n",
        "    return tweets.find(query).sort('interactions', -1)\n",
        "\n",
        "\n",
        "def top_10_tweets():\n",
        "    return tweets.find().sort('interactions', -1).limit(10)\n",
        "\n",
        "# Top 10 users orderer by follower counts \n",
        "# Direct postgreSQL Query into user_db \n",
        "def top_10_users():\n",
        "    top_10_users =  pd.read_sql_query('select * from \"user_db\" ORDER BY followers_count DESC LIMIT 10',con=conn)\n",
        "    return top_10_users\n",
        "\n",
        "# need to be optimzied \n",
        "def get_tweet_id_by_user_name(user_name):\n",
        "    user_db = pd.read_sql(\"SELECT * FROM user_db WHERE \",con=conn) # **** need to optimize\n",
        "    return list(user_db[user_db['screen_name'] == user_name]['tweet_ids'])\n",
        "\n",
        "\n",
        "def search_by_user(user_name):\n",
        "    tweet_ids = get_tweet_id_by_user_name(user_name)\n",
        "    #want a get_user_name_by_user_id for meta data\n",
        "    return get_tweet_by_ids(tweet_ids)\n",
        "  \n",
        "  "
      ],
      "metadata": {
        "id": "XyG6u3HOrh3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PNnr3vjmqTu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# JINWOO\"S EXPERIMENT"
      ],
      "metadata": {
        "id": "F-NQju5UqUUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('corona-out-2', \"r\") as f1:\n",
        "    for line in f1:\n",
        "        try:\n",
        "            data = json.loads(line)\n",
        "            myquery = { 'id': data['id'] }\n",
        "            mydoc = tweets.find(myquery)\n",
        "            tweet_data = data\n",
        "         \n",
        "            # storing to USER DB in PostgreSQL\n",
        "            ##########################################################\n",
        "            user_screen_names = get_user_screen_names()\n",
        "            user_tweet_ids = get_user_tweet_ids(tweet_data['user']['screen_name'])\n",
        "            if tweet_data['user']['screen_name'] in user_screen_names:\n",
        "                if tweet_data['id'] not in user_tweet_ids:\n",
        "                    update_tweet_ids_userdb(tweet_data['user']['screen_name'],tweet_data['id'])\n",
        "            else:\n",
        "                insert_to_userdb(tweet_data['user']['screen_name'], tweet_data['user']['id'], tweet_data['user']['followers_count'], [tweet_data['id']] )\n",
        "            ##########################################################\n",
        "\n",
        "            \n",
        "            # storing the tweeter data to MongoDB\n",
        "            if len(list(mydoc))==0:\n",
        "                user = data['user']\n",
        "                if ( data['text'].startswith('RT') ):\n",
        "                    retweet_data={'id':data['id'], 'created_at':get_JSON_date(data['created_at']), 'user_id':data['user']['id']}\n",
        "                    tdata=data['retweeted_status']\n",
        "                    myquery={'id':tdata['id']}\n",
        "                    original_tweet = tweets.find(myquery)\n",
        "                    if len(list(original_tweet))==0:\n",
        "                    # storing to USER DB in PostgreSQL\n",
        "                      ##########################################################\n",
        "                      user_screen_names = get_user_screen_names()\n",
        "                      user_tweet_ids = get_user_tweet_ids(tweet_data['user']['screen_name'])\n",
        "                      if tweet_data['user']['screen_name'] in user_screen_names:\n",
        "                        if tweet_data['id'] not in user_tweet_ids:\n",
        "                          update_tweet_ids_userdb(tweet_data['user']['screen_name'],tweet_data['id'])\n",
        "                        else:\n",
        "                          insert_to_userdb(tweet_data['user']['screen_name'], tweet_data['user']['id'], tweet_data['user']['followers_count'], [tweet_data['id']] )\n",
        "                     ##########################################################\n",
        "\n",
        "                        tweets.insert_one({'id':tdata['id'], 'text':tdata['text'], 'text_sorted':get_text_sorted(data['text']), 'created_at':get_JSON_date(tdata['created_at']), 'user_id':tdata['user']['id'], 'favorite_count':tdata['favorite_count'], 'retweet_count':tdata['retweet_count'], 'interactions':tdata['favorite_count']+tdata['retweet_count'], 'hashtags':get_hashtags_sorted([x['text'].lower() for x in tdata['entities']['hashtags']]), 'retweets':[retweet_data]})\n",
        "                    else:\n",
        "                        tweets.update_one(myquery, {'$push': {'retweets': retweet_data}})\n",
        "                else:\n",
        "                    tweets.insert_one({'id':data['id'], 'text':data['text'], 'text_sorted':get_text_sorted(data['text']), 'created_at':get_JSON_date(data['created_at']), 'user_id':data['user']['id'], 'favorite_count':data['favorite_count'], 'retweet_count':data['retweet_count'], 'interactions':data['favorite_count']+data['retweet_count'], 'hashtags':get_hashtags_sorted([x['text'].lower() for x in data['entities']['hashtags']]), 'retweets':list()})\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "LMJgfHSrqWOS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}